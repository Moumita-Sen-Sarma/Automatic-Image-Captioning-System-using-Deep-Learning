{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flask_deployment",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXr8z8lwhvKZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e0c6d2-319f-49ee-f84b-c5d7aa9d96ec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXbhql_CKkKR"
      },
      "source": [
        "### capture required models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so0uS-9HjwQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba96f2e-4721-495e-cf79-1dcc33fce4e5"
      },
      "source": [
        "!wget 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "!cp '/content/drive/MyDrive/image_cap/image captioning 8k/model_tokenizer' '/content'\n",
        "!cp '/content/drive/MyDrive/image_cap/image captioning 8k/Image_Caption_Generator.h5' '/content'\n",
        "!cp '/content/drive/MyDrive/image_cap/image captioning 8k/model.json' '/content'\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.applications import VGG16\n",
        "from keras import models\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import model_from_json\n",
        "import matplotlib.pyplot as plt\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "img_model_path = \"/content/vgg16_weights_tf_dim_ordering_tf_kernels.h5\"\n",
        "tokenizer_path = \"/content/model_tokenizer\"\n",
        "text_model_path = '/content/model.json'\n",
        "text_weight_path = '/content/Image_Caption_Generator.h5'\n",
        "\n",
        "def get_model(img_model_path):  \n",
        "  modelvgg = VGG16(include_top=True,weights=None)\n",
        "  ## load the locally saved weights \n",
        "  modelvgg.load_weights(img_model_path)\n",
        "  modelvgg._layers.pop()\n",
        "  modelvgg = models.Model(inputs=modelvgg.inputs, outputs=modelvgg.layers[-1].output)\n",
        "  return modelvgg\n",
        "\n",
        "def get_features(filename, img_model_path):\n",
        "  npix = 224 #image size is fixed at 224 because VGG16 model has been pre-trained to take that size.\n",
        "  target_size = (npix,npix,3)\n",
        "  data = np.zeros((1,npix,npix,3))\n",
        "  image = load_img(filename, target_size=target_size)\n",
        "      \n",
        "  image = img_to_array(image)\n",
        "  nimage = preprocess_input(image)\n",
        "  modelvgg = get_model(img_model_path)\n",
        "  y_pred = modelvgg.predict(nimage.reshape( (1,) + nimage.shape[:3]))\n",
        "  y_pred = y_pred.flatten()\n",
        "  new_image= np.array(y_pred.flatten().tolist())\n",
        "  return new_image\n",
        "\n",
        "def load_tokenizer(tokenizer_path):\n",
        "  with open(tokenizer_path, 'rb') as dct:\n",
        "    tokenizer=pickle.load(dct)\n",
        "  return tokenizer\n",
        "\n",
        "\n",
        "def load_text_model(text_model_path, text_weight_path):\n",
        "    json_file = open(text_model_path, 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    # load weights into new model\n",
        "    loaded_model.load_weights(text_weight_path)\n",
        "    return loaded_model\n",
        "\n",
        "def predict_caption(filename, img_model_path=img_model_path, tokenizer_path=tokenizer_path, \n",
        "                    text_model_path=text_model_path, text_weight_path=text_weight_path):\n",
        "    new_image = get_features(filename,img_model_path)\n",
        "    # print(new_image)\n",
        "    image = new_image.reshape(1,len(new_image))\n",
        "    tokenizer = load_tokenizer(tokenizer_path)\n",
        "    index_word = dict([(index,word) for word, index in tokenizer.word_index.items()])\n",
        "    in_text = 'startseq'\n",
        "    maxlen=30\n",
        "    for iword in range(maxlen):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence],maxlen)\n",
        "        model = load_text_model(text_model_path, text_weight_path)\n",
        "        yhat = model.predict([image,sequence],verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        newword = index_word[yhat]\n",
        "        in_text += \" \" + newword\n",
        "        if newword == \"endseq\":\n",
        "            break\n",
        "    return (in_text)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-16 11:35:30--  https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/64878964/b0afbae8-5983-11e6-90f4-e3db656bd548?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210316%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210316T113530Z&X-Amz-Expires=300&X-Amz-Signature=55d34db77a0ba80ed75cdacb66c84a41765d3166ad90dd0b7b9ea432c5fca43d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=64878964&response-content-disposition=attachment%3B%20filename%3Dvgg16_weights_tf_dim_ordering_tf_kernels.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-03-16 11:35:30--  https://github-releases.githubusercontent.com/64878964/b0afbae8-5983-11e6-90f4-e3db656bd548?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210316%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210316T113530Z&X-Amz-Expires=300&X-Amz-Signature=55d34db77a0ba80ed75cdacb66c84a41765d3166ad90dd0b7b9ea432c5fca43d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=64878964&response-content-disposition=attachment%3B%20filename%3Dvgg16_weights_tf_dim_ordering_tf_kernels.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 553467096 (528M) [application/octet-stream]\n",
            "Saving to: ‘vgg16_weights_tf_dim_ordering_tf_kernels.h5’\n",
            "\n",
            "vgg16_weights_tf_di 100%[===================>] 527.83M  56.7MB/s    in 8.9s    \n",
            "\n",
            "2021-03-16 11:35:40 (59.2 MB/s) - ‘vgg16_weights_tf_dim_ordering_tf_kernels.h5’ saved [553467096/553467096]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GocjDCLZKpuR"
      },
      "source": [
        "## flask webpage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAezTYG40gc7"
      },
      "source": [
        "!mkdir \"static\"\n",
        "!mkdir \"static/uploads\"\n",
        "!mkdir \"templates\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaT38Cvoij7T"
      },
      "source": [
        "!cp '/content/drive/MyDrive/image_cap/image captioning 8k/upload.html' 'templates'\n",
        "!cp '/content/drive/MyDrive/image_cap/image captioning 8k/image.jpg' \"static\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beNo3Ow8yjl4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44207f2a-055f-4302-b726-5b7707872bcd"
      },
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://i84hjlizzn-496ff2e9c6d22116-5000-colab.googleusercontent.com/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXQXemBmCVJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587b1998-e25b-4be7-8c22-e11ac1cfbbe1"
      },
      "source": [
        "import os\n",
        "# from app import app\n",
        "import urllib.request\n",
        "from flask import Flask, flash, request, redirect, url_for, render_template\n",
        "from werkzeug.utils import secure_filename\n",
        "from flask import Flask\n",
        "\n",
        "UPLOAD_FOLDER = 'static/uploads/'\n",
        "\n",
        "app = Flask(__name__)\n",
        "app.secret_key = \"secret key\"\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
        "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024\n",
        "\n",
        "\n",
        "ALLOWED_EXTENSIONS = set(['png', 'jpg', 'jpeg'])\n",
        "\n",
        "def allowed_file(filename):\n",
        "\treturn '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\t\n",
        "@app.route('/')\n",
        "def upload_form():\n",
        "\treturn render_template('upload.html')\n",
        "\n",
        "def get_class(filename):\n",
        "  path='/content/static/uploads/'\n",
        "  cap=predict_caption(path+filename)\n",
        "  cap=' '.join(cap.split()[1:-1])\n",
        "  # flash(cap)\n",
        "  return cap\n",
        "\n",
        "@app.route('/', methods=['POST'])\n",
        "def upload_image():\n",
        "    if 'file' not in request.files:\n",
        "        flash('No file part')\n",
        "        return render_template('upload.html')\n",
        "    file = request.files['file']\n",
        "    if file.filename == '':\n",
        "        flash('No image selected for uploading')\n",
        "        return render_template('upload.html')\n",
        "    if file and allowed_file(file.filename):\n",
        "        filename = secure_filename(file.filename)\n",
        "        file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
        "        flash('Image successfully uploaded and displayed below')\n",
        "        pred=get_class(filename)\n",
        "        return render_template('upload.html', filename=filename, pred=pred)\n",
        "\n",
        "    else:\n",
        "        \n",
        "        flash('Allowed image types are -> png, jpg, jpeg')\n",
        "        # return redirect(request.url)\n",
        "        return render_template('upload.html')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
            "127.0.0.1 - - [16/Mar/2021 11:35:56] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [16/Mar/2021 11:35:57] \"\u001b[37mGET /static/image.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [16/Mar/2021 11:35:57] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [16/Mar/2021 11:37:19] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [16/Mar/2021 11:37:20] \"\u001b[37mGET /static/uploads/dog-puppy-on-garden-royalty-free-image-1586966191.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [16/Mar/2021 11:37:20] \"\u001b[37mGET /static/image.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [16/Mar/2021 11:37:21] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C8Bfk9IDUEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2534cd09-c2d4-4fa7-bc3c-bd9fb2e1571c"
      },
      "source": [
        "ALLOWED_EXTENSIONS = set(['png', 'jpg', 'jpeg'])\n",
        "files=['abc.jpg','xyz.pdf','cat.png', 'animal.jpeg','record.xlsx']\n",
        "c=0\n",
        "def allowed_file(filename):\n",
        "\treturn '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "for filename in files:\n",
        "  if allowed_file(filename):\n",
        "      print('Given file: '+ filename)\n",
        "      print('file format: '+filename.rsplit('.', 1)[1].lower()+ ': '+str(c)+ '--extension allowed')\n",
        "      print('--------------------------------------------------------------------------')\n",
        "\n",
        "  else:\n",
        "      print('Given file: '+ filename)\n",
        "      print('file format: '+filename.rsplit('.', 1)[1].lower()+ ': '+str(c)+ '--extension not allowed')\n",
        "      print('--------------------------------------------------------------------------')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Given file: abc.jpg\n",
            "file format: jpg: 0--extension allowed\n",
            "--------------------------------------------------------------------------\n",
            "Given file: xyz.pdf\n",
            "file format: pdf: 0--extension not allowed\n",
            "--------------------------------------------------------------------------\n",
            "Given file: cat.png\n",
            "file format: png: 0--extension allowed\n",
            "--------------------------------------------------------------------------\n",
            "Given file: animal.jpeg\n",
            "file format: jpeg: 0--extension allowed\n",
            "--------------------------------------------------------------------------\n",
            "Given file: record.xlsx\n",
            "file format: xlsx: 0--extension not allowed\n",
            "--------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phjYaWYWtWxv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}